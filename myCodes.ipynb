{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analying Jeopardy (the TV show) Dataset\n",
    "In this analysis, the historical questions/answers from Jeopardy are to be analyzed to determine if any particular patterns existed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import string\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Show Number    Air Date      Round                         Category  Value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
      "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
      "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
      "\n",
      "                                            Question      Answer  \n",
      "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
      "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
      "2  The city of Yuma in this state has a record av...     Arizona  \n",
      "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
      "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  \n",
      "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "print(jeopardy.head(5))\n",
    "print(jeopardy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# notice that some column names contain spaces; clean the column names...\n",
    "jeopardy.columns = ['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question', 'Answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
      "       'Answer'],\n",
      "      dtype='object')\n",
      "   Show Number    Air Date      Round                         Category Value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY  $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
      "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
      "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
      "\n",
      "                                            Question      Answer  \n",
      "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
      "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
      "2  The city of Yuma in this state has a record av...     Arizona  \n",
      "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
      "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  \n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "print(jeopardy.columns)\n",
    "print(jeopardy.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# before analysis can be performed, we need to clean/normalize the current data\n",
    "\n",
    "# create a function to perform normalization text\n",
    "def normalize_text(data):\n",
    "    # build the punctuation table for translation\n",
    "    punc_table = str.maketrans('', '', string.punctuation)\n",
    "    # remove the punctuations\n",
    "    new_data = data.lower().translate(punc_table)\n",
    "    return new_data\n",
    "\n",
    "# create a function to normalize the 'Value' data into numerics\n",
    "def normalize_value(data):\n",
    "    try:\n",
    "        new_data = normalize_text(data)\n",
    "        new_data = int(new_data)\n",
    "    except:\n",
    "        new_data = 0\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalize 'Question', 'Answer', and 'Value'\n",
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize_text)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize_text)\n",
    "jeopardy['clean_value'] = jeopardy['Value'].apply(normalize_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalize 'Air Date' into datetime format\n",
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How often the answer is deducible from the question?\n",
    "To analyze this question, we measure how many times word in the answer also occur in its corresponding question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that calculate, for each question, what percentage\n",
    "# of the words in its answer also appear in its question\n",
    "def analyze1(row):\n",
    "    split_answer = row['clean_answer'].split(' ')\n",
    "    split_question = row['clean_question'].split(' ')\n",
    "    split_answer_dropped = [each for each in split_answer if each != 'the' and each != '']\n",
    "    match_count = 0\n",
    "    if len(split_answer_dropped) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        for each_answer in split_answer_dropped:\n",
    "            if each_answer in split_question:\n",
    "                match_count += 1\n",
    "        result = match_count / len(split_answer_dropped)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply the above function across all rows\n",
    "jeopardy['answer_in_question'] = jeopardy.apply(analyze1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0582069615746\n",
      "2485\n"
     ]
    }
   ],
   "source": [
    "# find the average for 'answer_in_question'\n",
    "print(jeopardy['answer_in_question'].mean())\n",
    "\n",
    "# find the number of rows where 'answer_in_question' > 0\n",
    "print(jeopardy[jeopardy['answer_in_question'] > 0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings So Far\n",
    "Out of the 20000 historical questions, 2485 (~12.4%) of them had words in their answers also appear in their questions.\n",
    "\n",
    "However, most of the answers contain multiple words, and thus, on average, approximately 5.82% of all the words in answers appear in the questions.\n",
    "\n",
    "Even though the probabilites are rather low, when desperate, it may be useful to look for answers that have the keywords from the questions.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How often are the new questions repeats of past questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Show Number   Air Date            Round         Category Value  \\\n",
      "19325           10 1984-09-21  Final Jeopardy!  U.S. PRESIDENTS  None   \n",
      "\n",
      "                                                Question              Answer  \\\n",
      "19325  Adventurous 26th president, he was 1st to ride...  Theodore Roosevelt   \n",
      "\n",
      "                                          clean_question        clean_answer  \\\n",
      "19325  adventurous 26th president he was 1st to ride ...  theodore roosevelt   \n",
      "\n",
      "       clean_value  answer_in_question  \n",
      "19325            0                 0.0  \n",
      "      Show Number   Air Date      Round         Category Value  \\\n",
      "1922         6294 2012-01-19  Jeopardy!  THAT'S BUSINESS  $400   \n",
      "\n",
      "                                               Question   Answer  \\\n",
      "1922  In 1997 Tyco International moved to this U.K. ...  Bermuda   \n",
      "\n",
      "                                         clean_question clean_answer  \\\n",
      "1922  in 1997 tyco international moved to this uk te...      bermuda   \n",
      "\n",
      "      clean_value  answer_in_question  \n",
      "1922          400                 0.0  \n"
     ]
    }
   ],
   "source": [
    "# first sort by 'Air Date' in ascending order\n",
    "jeopardy.sort_values(by='Air Date',inplace=True,ascending=True)\n",
    "\n",
    "# check sorted dataframe, confirm that last row has a later date than first row\n",
    "print(jeopardy.head(1))\n",
    "print(jeopardy.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each row, calculate the percentage of complex words in questions that have\n",
    "  # appeared before\n",
    "question_overlap = []\n",
    "terms_used = set()\n",
    "for idx, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split(' ')\n",
    "    split_question = [each for each in split_question if len(each) >= 6]\n",
    "    match_count = 0\n",
    "    for each in split_question:\n",
    "        if each in terms_used:\n",
    "            match_count += 1\n",
    "        terms_used.add(each)\n",
    "    if len(split_question) > 0:\n",
    "        result = match_count / len(split_question)\n",
    "    question_overlap.append(result)\n",
    "jeopardy['question_overlap'] = question_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70327187421603465"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean for 'question_overlap'\n",
    "jeopardy['question_overlap'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings So Far\n",
    "On average, 70% of the complex words (those with at least 6 characters) have appeared at one point or another in the history of Jeopardy.\n",
    "\n",
    "This is interesting as it indicates that it is likely complex words in future questions may have already appeared in the question sets before, and thus contestants may use the historical questions as references to prepare in advance.\n",
    "\n",
    "Nonetheless, it may be useful to further identify the natures of these complex words.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which words are associated with high / low values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to determine whether a row is of high value (over $800)\n",
    "def value(row):\n",
    "    if row['clean_value'] > 800:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply the above function across the dataframe\n",
    "jeopardy['high_value'] = jeopardy.apply(value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a function that determine the frequencies of a word appearing in\n",
    "# high and low value questions\n",
    "def word_value(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for idx, row in jeopardy.iterrows():\n",
    "        splitted = row['clean_question'].split(' ')\n",
    "        if word in splitted:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blancmange', 'pacific', 'dumber', 'michaelmas', 'riyadh']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample 5 words from the previously generated 'terms_used'\n",
    "comparison_terms = list(terms_used)[0:5]\n",
    "comparison_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (9, 28), (0, 1), (0, 1), (0, 1)]\n"
     ]
    }
   ],
   "source": [
    "# generate a list of observed frequencies in both high/low value questions\n",
    "# for those 5 words\n",
    "observed_expected = []\n",
    "for each in comparison_terms:\n",
    "    observed_expected.append(word_value(each))\n",
    "print(observed_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing expected counts and chi-squared value for the sampled words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5734 14265\n"
     ]
    }
   ],
   "source": [
    "# calculate the number of questions that are either of high value or low value\n",
    "high_value_count = jeopardy[jeopardy['high_value'] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy['high_value'] == 0].shape[0]\n",
    "print(high_value_count, low_value_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for each of the 5 sampled words, calculate their chi-squared / p-value\n",
    "# based on their observed frequencies (calculated previously) and their\n",
    "# expected frequencies (to be calculated below)\n",
    "from scipy.stats import chisquare\n",
    "chi_squared = []\n",
    "for each in observed_expected:\n",
    "    total = sum(each)\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    expected_high_count = total_prop * high_value_count\n",
    "    expected_low_count = total_prop * low_value_count\n",
    "    chi2_value, p_value = chisquare(each, (expected_high_count, expected_low_count))\n",
    "    chi_squared.append((chi2_value, p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.4877921171956752, 0.11473257634454047),\n",
       " (0.34189277990072214, 0.55873870578406826),\n",
       " (0.40196284612688399, 0.52607729857054686),\n",
       " (0.40196284612688399, 0.52607729857054686),\n",
       " (0.40196284612688399, 0.52607729857054686)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the chi-squared values and p-values\n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings So Far\n",
    "First of all, the sampled frequencies were rather low, ranging from 0 occurences to 2 occurences across both high/low value questions. Therefore, the statistical outcomes would be questionable at best.\n",
    "\n",
    "Secondly, taking the chi-squared statistics at face values. None of the outcomes exhibited significant differences. In other words, there were no differences in their likliehood of appearances in either high-value questions or low-value questions.\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
